{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be766f76",
   "metadata": {},
   "source": [
    "# Análisis reproducible — predicción de `total_alquileres` por hora\n",
    "\n",
    "Este cuaderno contiene: EDA, preprocesado mínimo, entrenamiento rápido de una línea base, evaluación y ejemplo de llamada a la API.\n",
    "\n",
    "Notas:\n",
    "- Ajusta las rutas si tu CSV está en otra ubicación (`dataset_alquiler.csv` en la raíz del repo).\n",
    "- El cuaderno está pensado para ejecutarse en un entorno con las dependencias del proyecto instaladas. Si alguna librería falta, instala con `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f39508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: imports básicos\n",
    "import os\n",
    "markdown\n",
    "a1b2c3d4\n",
    "markdown\n",
    "# Análisis reproducible — predicción de `total_alquileres` por hora\n",
    "Este cuaderno sigue un flujo humano y detallado: inspección, limpieza exhaustiva, EDA, modelado rápido, evaluación y diagnóstico visual.\n",
    "\n",
    "Notas: ejecuta esto en el entorno del proyecto y asegúrate de tener `requirements.txt` instalado si faltan paquetes.\n",
    "markdown\n",
    "intro-2\n",
    "markdown\n",
    "## 1) Importar librerías y configuración inicial — pequeño bloque explicativo\n",
    "code\n",
    "imp-1\n",
    "python\n",
    "# Imports y configuración\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, confusion_matrix\n",
    "import joblib\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "markdown\n",
    "load-desc\n",
    "markdown\n",
    "## 2) Cargar datos — detectando la columna `fecha` si existe y mostrando primeras impresiones\n",
    "code\n",
    "load-1\n",
    "python\n",
    "DATA_PATH = Path('dataset_alquiler.csv')\n",
    "assert DATA_PATH.exists(), f'Dataset no encontrado en {DATA_PATH}. Coloca `dataset_alquiler.csv` en la raíz.'\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "# detectar columna fecha y normalizar nombre\n",
    "for col in ['fecha','Fecha','date','timestamp','datetime']:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            df = df.rename(columns={col: 'fecha'})\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "print('Dimensiones:', df.shape)\n",
    "display(df.head())\n",
    "markdown\n",
    "clean-desc\n",
    "markdown\n",
    "## 3) Limpieza exhaustiva (paso a paso)\n",
    "Descripción: borrar duplicados, convertir tipos, tratar nulos con estrategia razonable, detección y tratamiento de outliers, normalizar nombres de columnas y crear variables temporales.\n",
    "code\n",
    "clean-1\n",
    "python\n",
    "df_clean = df.copy()\n",
    "# Normalizar nombres: quitar espacios y pasar a minusculas\n",
    "df_clean.columns = [c.strip().lower().replace(' ', '_') for c in df_clean.columns]\n",
    "# 1) Duplicados\n",
    "n_dup = df_clean.duplicated().sum()\n",
    "print(f'Duplicados detectados: {n_dup}')\n",
    "if n_dup>0:\n",
    "    df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
    "# 2) Tipos básicos y nulos\n",
    "for c in df_clean.select_dtypes(include=['object']).columns:\n",
    "    # intentar convertir a num si es posible\n",
    "    try:\n",
    "        df_clean[c] = pd.to_numeric(df_clean[c].str.replace(',','.'), errors='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "# convertir fecha si existe\n",
    "if 'fecha' in df_clean.columns:\n",
    "    df_clean['fecha'] = pd.to_datetime(df_clean['fecha'], errors='coerce')\n",
    "# 3) Imputación razonable: para num -> mediana; para categóricas -> 'missing'\n",
    "num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in df_clean.columns if c not in num_cols and c!='fecha']\n",
    "for c in num_cols:\n",
    "    med = df_clean[c].median(skipna=True)\n",
    "    df_clean[c] = df_clean[c].fillna(med)\n",
    "for c in cat_cols:\n",
    "    df_clean[c] = df_clean[c].fillna('missing')\n",
    "# 4) tratar outliers simples: winsorize al 1% / 99% para numeric con método robusto\n",
    "from scipy.stats import mstats\n",
    "for c in num_cols:\n",
    "    try:\n",
    "        df_clean[c] = mstats.winsorize(df_clean[c], limits=[0.01, 0.01])\n",
    "    except Exception:\n",
    "        pass\n",
    "# 5) crear features temporales si fecha existe\n",
    "if 'fecha' in df_clean.columns:\n",
    "    df_clean['hour'] = df_clean['fecha'].dt.hour\n",
    "    df_clean['dayofweek'] = df_clean['fecha'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['fecha'].dt.month\n",
    "# resumen limpieza\n",
    "print('Post-limpieza shape:', df_clean.shape)\n",
    "display(df_clean.head())\n",
    "markdown\n",
    "eda-desc\n",
    "markdown\n",
    "## 4) EDA visual — matriz de correlación, distribución objetivo, series temporales y más\n",
    "code\n",
    "eda-1\n",
    "python\n",
    "# Correlation matrix para variables numéricas\n",
    "num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(num_cols) > 1:\n",
    "    corr = df_clean[num_cols].corr()\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "    plt.title('Matriz de correlación (numéricas)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Pocas variables numéricas para correlación')\n",
    "code\n",
    "eda-2\n",
    "python\n",
    "# Distribución del objetivo\n",
    "target = 'total_alquileres' if 'total_alquileres' in df_clean.columns else (num_cols[-1] if num_cols else None)\n",
    "if target is not None:\n",
    "    plt.figure()\n",
    "    sns.histplot(df_clean[target], kde=True, bins=50)\n",
    "    plt.title(f'Distribución de {target}')\n",
    "    plt.show()\n",
    "    print('Estadísticos objetivo:')\n",
    "    display(df_clean[target].describe())\n",
    "else:\n",
    "    print('No se detectó objetivo numérico')\n",
    "code\n",
    "eda-3\n",
    "python\n",
    "# Series temporales por hora (promedio) si fecha está presente\n",
    "if 'fecha' in df_clean.columns and target in df_clean.columns:\n",
    "    ts = df_clean.set_index('fecha').resample('H')[target].mean().fillna(0)\n",
    "    plt.figure(figsize=(14,4))\n",
    "    ts.plot()\n",
    "    plt.title('Serie temporal: promedio por hora')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Serie temporal no disponible (falta fecha o objetivo)')\n",
    "markdown\n",
    "model-desc\n",
    "markdown\n",
    "## 5) Modelado rápido y diagnóstico — RandomForest baseline y visualizaciones de calidad\n",
    "code\n",
    "model-1\n",
    "python\n",
    "# Preparar X/y\n",
    "features = [c for c in df_clean.columns if c != target and c != 'fecha']\n",
    "X = df_clean[features].select_dtypes(include=[np.number]).fillna(0)\n",
    "y = df_clean[target].fillna(0)\n",
    "print('X shape, y shape:', X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, pred, squared=False))\n",
    "print('MAE:', mean_absolute_error(y_test, pred))\n",
    "print('R2:', r2_score(y_test, pred))\n",
    "code\n",
    "vis-1\n",
    "python\n",
    "# Pred vs Real y residuos\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, pred, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Predicho')\n",
    "plt.title('Predicho vs Real')\n",
    "plt.show()\n",
    "# Residuals\n",
    "res = y_test - pred\n",
    "plt.figure()\n",
    "sns.histplot(res, kde=True, bins=50)\n",
    "plt.title('Distribución de residuos')\n",
    "plt.show()\n",
    "code\n",
    "confusion-1\n",
    "python\n",
    "# Matriz de confusión mediante discretización en quantiles (útil como diagnóstico)\n",
    "try:\n",
    "    n_bins = 5\n",
    "    bins = pd.qcut(y_test, q=n_bins, labels=False, duplicates='drop')\n",
    "    pred_bins = pd.qcut(pd.Series(pred), q=n_bins, labels=False, duplicates='drop')\n",
    "    cm = confusion_matrix(bins, pred_bins)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicho (bin)')\n",
    "    plt.ylabel('Real (bin)')\n",
    "    plt.title('Matriz de confusión en bins (quantiles)')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('No fue posible calcular matriz de confusión por bins:', e)\n",
    "code\n",
    "featimp\n",
    "python\n",
    "# Importancias de features\n",
    "try:\n",
    "    imp = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    display(imp.head(20))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=imp.head(20), y=imp.head(20).index)\n",
    "    plt.title('Importancia de características (RandomForest)')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('No se pudo calcular importancias:', e)\n",
    "code\n",
    "shap-try\n",
    "python\n",
    "# SHAP (opcional): intentar si está instalado y el modelo es compatible\n",
    "try:\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('SHAP no disponible o falló (instala shap y dependencias nativas):', e)\n",
    "markdown\n",
    "save-concl\n",
    "markdown\n",
    "## Guardar modelo y conclusiones rápidas\n",
    "El modelo baseline (RandomForest) se guarda para referencia rápida; recuerda que para producción conviene usar HPO y validación temporal adecuada.\n",
    "code\n",
    "save-1\n",
    "python\n",
    "out_dir = Path('models')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "joblib.dump(model, out_dir / 'notebook_baseline.joblib')\n",
    "print('Modelo guardado en models/notebook_baseline.joblib')\n",
    "markdown\n",
    "ending\n",
    "markdown\n",
    "---\n",
    "Si deseas, puedo ejecutar este notebook aquí y adjuntar las figuras y salidas (necesito que el entorno tenga las dependencias instaladas). También puedo embellecer las celdas con más narrativa y conclusiones específicas basadas en los resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
